{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe37fc99",
   "metadata": {},
   "source": [
    "# Vocabulary (or \"vocab\") and string matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f0a012",
   "metadata": {},
   "source": [
    "Vocabulary (or \"vocab\") and string matching are essential concepts in Natural Language Processing (NLP), which is a field of artificial intelligence that focuses on the interaction between computers and human language. These concepts are fundamental for various NLP tasks, such as text processing, information retrieval, and text analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f02559",
   "metadata": {},
   "source": [
    "## Vocabulary (Vocab):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9187cff3",
   "metadata": {},
   "source": [
    "In NLP, the vocabulary refers to the set of unique words or tokens that exist in a particular corpus or dataset. A corpus can be a collection of documents, articles, or any text data.\n",
    "The size and composition of the vocabulary are crucial for many NLP tasks, including text classification, sentiment analysis, and language modeling. A larger vocabulary can capture more nuances in language, but it can also make models more complex and computationally expensive.\n",
    "Vocabularies are often used to create word embeddings, such as Word2Vec or GloVe, which represent words as vectors in high-dimensional spaces. These embeddings are essential for various NLP applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53539bf1",
   "metadata": {},
   "source": [
    "### String Matching:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac224f0",
   "metadata": {},
   "source": [
    "String matching in NLP involves finding occurrences of specific strings within a text or comparing strings for similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a873ae5",
   "metadata": {},
   "source": [
    "Exact string matching: \n",
    "    \n",
    "    \n",
    "    Determining if an exact string or substring exists in a given text. This can be done using simple methods like the in operator in Python or more advanced algorithms like the Knuth-Morris-Pratt algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842a7cb9",
   "metadata": {},
   "source": [
    "Fuzzy string matching: \n",
    "    \n",
    "    Identifying strings that are approximately equal, taking into account typos, misspellings, and variations. Algorithms like Levenshtein distance or Jaccard similarity are often used for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54121311",
   "metadata": {},
   "source": [
    "Regular expressions: \n",
    "    \n",
    "    Regular expressions (regex) provide a powerful way to define patterns for string matching. They are widely used for text extraction and manipulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc19ccf8",
   "metadata": {},
   "source": [
    "Token-based matching: \n",
    "\n",
    "    In NLP, matching is often done at the token level, where tokens are words or subwords. Token-based matching can involve comparing tokens based on exact or approximate matches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d000f164",
   "metadata": {},
   "source": [
    "# Rules based Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f65185",
   "metadata": {},
   "source": [
    "SpaCy is a popular Python library for natural language processing (NLP). It provides a range of features and tools for working with text data. The Matcher and PhraseMatcher are two components of SpaCy that are used for specific text pattern matching tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d99674",
   "metadata": {},
   "source": [
    "## Matcher:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b59218",
   "metadata": {},
   "source": [
    "The Matcher in SpaCy is used for rule-based, token-level pattern matching in text. It allows you to define rules to find sequences of tokens based on their attributes (e.g., part of speech, text, or other custom attributes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa48ce77",
   "metadata": {},
   "source": [
    "Use cases of the Matcher include:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe78ec4b",
   "metadata": {},
   "source": [
    "Entity Recognition:\n",
    "    \n",
    "    You can create rules to identify and extract specific entities in text, such as dates, addresses, or custom domain-specific terms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c83f55b",
   "metadata": {},
   "source": [
    "Information Extraction:\n",
    "    \n",
    "    It is commonly used to extract structured information from unstructured text by defining patterns for specific data like phone numbers, email addresses, or product codes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d574505",
   "metadata": {},
   "source": [
    "Custom Text Analysis:\n",
    "    \n",
    "    You can define rules to find specific phrases or patterns that are relevant to your NLP task, such as finding mentions of medical conditions in a healthcare context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78df767f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform standard imports\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2375443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7702723889527052641 0 2 Data science\n",
      "7702723889527052641 6 9 data-science\n",
      "7702723889527052641 15 17 data science\n"
     ]
    }
   ],
   "source": [
    "# Import commands of  the Matcher library\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "\n",
    "## Write pattern\n",
    "pattern_1= [{\"LOWER\": \"data\"}, {\"LOWER\": \"science\"}]\n",
    "pattern_2= [{\"LOWER\": \"data\"},{'IS_PUNCT': True}, {\"LOWER\": \"science\"}]\n",
    "matcher.add(\"DataSciencePattern\", [pattern_1,pattern_2])\n",
    "\n",
    "\n",
    "#text\n",
    "text = \"Data science is a field of data-science, and it involves data data data science.\"\n",
    "\n",
    "\n",
    "## entity/vocab matching\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    span = doc[start:end]\n",
    "    \n",
    "    ## The `match_id` is simply the hash value of the `string_ID` 'VOCAB'\n",
    "    ##start and end are the location where we found our match in the text\n",
    "    print(match_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e48e8072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7702723889527052641 0 2 Data science\n",
      "7702723889527052641 6 9 data-science\n",
      "7702723889527052641 13 15 data science\n"
     ]
    }
   ],
   "source": [
    "## Write pattern\n",
    "pattern_1= [{\"LOWER\": \"data\"}, {\"LOWER\": \"science\"}]\n",
    "\n",
    "#if we want to find the form of verb like 2nd and 3rd then at the last we use lemma insted of LOWER.\n",
    "pattern_2= [{\"LOWER\": \"data\"},{'IS_PUNCT': True}, {\"LOWER\": \"science\"}]\n",
    "matcher.add(\"DataSciencePattern\", [pattern_1,pattern_2])\n",
    "\n",
    "\n",
    "#text\n",
    "text = \"Data science is a field of data-science, and it involves data science.\"\n",
    "\n",
    "\n",
    "## entity/vocab matching\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    span = doc[start:end]\n",
    "    \n",
    "    ## The `match_id` is simply the hash value of the `string_ID` 'VOCAB'\n",
    "    ##start and end are the location where we found our match in the text\n",
    "    print(match_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab26b840",
   "metadata": {},
   "source": [
    "# Token wildcard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5175e141",
   "metadata": {},
   "source": [
    "When we want to extract the vocab after the specific char we use this. Like below we want to extract the # all char."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef075054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#data\n",
      "#involves\n",
      "#science\n"
     ]
    }
   ],
   "source": [
    "pattern=[{'ORTH': '#'}, {}]\n",
    "matcher.remove('DataSciencePattern')\n",
    "matcher.add(\"DataSciencePattern\", [pattern])\n",
    "\n",
    "#text\n",
    "text = \"Data science is a field of #data-science, and it #involves data #science.\"\n",
    "\n",
    "\n",
    "## entity/vocab matching\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    span = doc[start:end]\n",
    "    print(span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4733a276",
   "metadata": {},
   "source": [
    "# PhraseMatcher:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9bd9c0",
   "metadata": {},
   "source": [
    "The PhraseMatcher in SpaCy is specifically designed for matching a list of phrases (or terms) in the text. It is more efficient for large lists of phrases compared to the regular Matcher."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9afc70f",
   "metadata": {},
   "source": [
    "Use cases of the PhraseMatcher include:\n",
    "    \n",
    "    Named Entity Recognition (NER): \n",
    "        \n",
    "        You can match and extract specific entities based on a predefined list of names or terms, such as matching a list of cities or organization names.\n",
    "        \n",
    "        \n",
    "     Custom Named Entity Recognition: \n",
    "     \n",
    "     You can use it to identify and extract custom domain-specific entities using a predefined list of phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "012f4241",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "phrase_matcher = PhraseMatcher(nlp.vocab, attr='LOWER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ea56bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York\n",
      "Los Angeles\n",
      "San Francisco\n"
     ]
    }
   ],
   "source": [
    "phrases = [\"New York\", \"Los Angeles\", \"San Francisco\"]\n",
    "patterns = [nlp(text) for text in phrases]\n",
    "phrase_matcher.add(\"CityMatcher\",patterns)  # Pass the list of patterns as a single argument\n",
    "\n",
    "text = \"New York, Los Angeles, and San Francisco are major cities.\"\n",
    "doc = nlp(text)\n",
    "matches = phrase_matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    span = doc[start:end]\n",
    "    print(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3ae683a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuzzy Matches:\n",
      "banana\n"
     ]
    }
   ],
   "source": [
    "import Levenshtein\n",
    "\n",
    "# Define a list of target strings\n",
    "target_strings = [\"apple\", \"banana\", \"cherry\", \"date\", \"elderberry\"]\n",
    "\n",
    "# Input string with a potential typo\n",
    "input_string = \"banama\"\n",
    "\n",
    "# Set a threshold for similarity\n",
    "threshold = 3  # You can adjust this threshold based on your needs\n",
    "\n",
    "# Initialize a list to store matched strings\n",
    "matches = []\n",
    "\n",
    "# Perform fuzzy matching\n",
    "for target in target_strings:\n",
    "    distance = Levenshtein.distance(input_string, target)\n",
    "    if distance <= threshold:\n",
    "        matches.append(target)\n",
    "\n",
    "# Print the matched strings\n",
    "print(\"Fuzzy Matches:\")\n",
    "for match in matches:\n",
    "    print(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1318819",
   "metadata": {},
   "source": [
    "# NAMED Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75b1625f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "320634f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla | ORG | Companies, agencies, institutions, etc.\n",
      "over $94B | MONEY | Monetary values, including unit\n",
      "2024 | DATE | Absolute or relative dates or periods\n",
      "Jeff Bezos | PERSON | People, including fictional\n",
      "Elon Musk’s | WORK_OF_ART | Titles of books, songs, etc.\n"
     ]
    }
   ],
   "source": [
    "doc=nlp('Tesla has lost over $94B in market valuation so far in 2024, and Jeff Bezos is threatening to steal Elon Musk’s crown as the world’s richest person')\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text,'|',ent.label_,'|',spacy.explain(ent.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6648188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tesla\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " has lost \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    over $94B\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       " in market valuation so far in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2024\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", and \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Jeff Bezos\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is threatening to steal \n",
       "<mark class=\"entity\" style=\"background: #f0d0ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Elon Musk’s\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">WORK_OF_ART</span>\n",
       "</mark>\n",
       " crown as the world’s richest person</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc,style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd34bac",
   "metadata": {},
   "source": [
    "So if we see above that Elon Musk's is not considered as Person, so we can say that Spacy not always work , so in that case we can train spacy like below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "892c134a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span\n",
    "\n",
    "t1=Span(doc,21,24,label='PERSON')\n",
    "\n",
    "doc.set_ents([t1],default='unmodified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8a5de7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tesla\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " has lost \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    over $94B\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       " in market valuation so far in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2024\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", and \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Jeff Bezos\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is threatening to steal \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Elon Musk’s\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " crown as the world’s richest person</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc,style='ent')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
